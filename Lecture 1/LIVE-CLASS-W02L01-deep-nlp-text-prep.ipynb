{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69383602-32d0-44b4-86d5-a29d46674555",
   "metadata": {},
   "source": [
    "# AML Week 2, Lecture 1: Preparing Text for Deep NLP Models (TextVectorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36e37a1-8e2d-49f0-9652-39896926fd19",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc57c4f-3b2c-4f6f-86aa-68f474a45656",
   "metadata": {},
   "source": [
    "- How to create a train-test-val split for Tensorflow datasets from a train-test split. \n",
    "- How to use a Keras TextVectorization Layer\n",
    "- Demonstrate how tensorflow models using Sequences with Embedding Layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a3487b0-db87-4f70-bc6c-a48e62956740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding parent directory to python path\n",
    "import sys, os\n",
    "sys.path.append( os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23f8d776-63e5-4a02-afd8-04628e4c858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the autoreload extension\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import custom_functions_SOLUTION  as fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90fe76e-5fa7-436e-9634-d67e5b470eab",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d36b5806-1bf5-4c55-8e39-3f9159e26d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Amazon Product Reviews\n",
       "\n",
       "- URL: https://cseweb.ucsd.edu/~jmcauley/datasets.html#amazon_reviews \n",
       "\n",
       "## Description\n",
       "\n",
       "This is a large crawl of product reviews from Amazon. This dataset contains 82.83 million unique reviews, from around 20 million users.\n",
       "\n",
       "## Basic statistics\n",
       "\n",
       "| Ratings:  | 82.83 million        |\n",
       "| --------- | -------------------- |\n",
       "| Users:    | 20.98 million        |\n",
       "| Items:    | 9.35 million         |\n",
       "| Timespan: | May 1996 - July 2014 |\n",
       "\n",
       "## Metadata\n",
       "\n",
       "- reviews and ratings\n",
       "- item-to-item relationships (e.g. \"people who bought X also bought Y\")\n",
       "- timestamps\n",
       "- helpfulness votes\n",
       "- product image (and CNN features)\n",
       "- price\n",
       "- category\n",
       "- salesRank\n",
       "\n",
       "## Example\n",
       "\n",
       "```\n",
       "{  \"reviewerID\": \"A2SUAM1J3GNN3B\",  \"asin\": \"0000013714\",  \"reviewerName\": \"J. McDonald\",  \"helpful\": [2, 3],  \"reviewText\": \"I bought this for my husband who plays the piano.  He is having a wonderful time playing these old hymns.  The music  is at times hard to read because we think the book was published for singing from more than playing from.  Great purchase though!\",  \"overall\": 5.0,  \"summary\": \"Heavenly Highway Hymns\",  \"unixReviewTime\": 1252800000,  \"reviewTime\": \"09 13, 2009\" }\n",
       "```\n",
       "\n",
       "## Download link\n",
       "\n",
       "See the [Amazon Dataset Page](https://cseweb.ucsd.edu/~jmcauley/datasets/amazon_v2/) for download information.\n",
       "\n",
       "The 2014 version of this dataset is [also available](https://cseweb.ucsd.edu/~jmcauley/datasets/amazon/links.html).\n",
       "\n",
       "## Citation\n",
       "\n",
       "Please cite the following if you use the data:\n",
       "\n",
       "**Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering**\n",
       "\n",
       "R. He, J. McAuley\n",
       "\n",
       "*WWW*, 2016\n",
       "[pdf](https://cseweb.ucsd.edu/~jmcauley/pdfs/www16a.pdf)\n",
       "\n",
       "**Image-based recommendations on styles and substitutes**\n",
       "\n",
       "J. McAuley, C. Targett, J. Shi, A. van den Hengel\n",
       "\n",
       "*SIGIR*, 2015\n",
       "[pdf](https://cseweb.ucsd.edu/~jmcauley/pdfs/sigir15.pdf)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "with open(\"../Data-AmazonReviews/Amazon Product Reviews.md\") as f:\n",
    "    display(Markdown(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f7e2ff-dcf2-4b44-addc-6215aa8a9223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# Then Set Random Seeds\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "# Then run the Enable Deterministic Operations Function\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# MacOS Sonoma Fix\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89879753-84c6-40cb-a2a8-8d6e7221cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')\n",
    "pd.set_option('display.max_colwidth', 250)\n",
    "\n",
    "# Define a function for building an LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, optimizers, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b67cf1a-97b6-4d3b-b103-694e4a6c6c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8191 entries, 0 to 8256\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   overall            8191 non-null   float64\n",
      " 1   text-raw           8191 non-null   object \n",
      " 2   length             8191 non-null   int64  \n",
      " 3   text               8191 non-null   object \n",
      " 4   lower_text         8191 non-null   object \n",
      " 5   tokens             8191 non-null   object \n",
      " 6   no_stops           8191 non-null   object \n",
      " 7   no_stops_no_punct  8191 non-null   object \n",
      " 8   spacy_lemmas       8191 non-null   object \n",
      " 9   bigrams            8191 non-null   object \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 703.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>text-raw</th>\n",
       "      <th>length</th>\n",
       "      <th>text</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>no_stops</th>\n",
       "      <th>no_stops_no_punct</th>\n",
       "      <th>spacy_lemmas</th>\n",
       "      <th>bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Not going to show you the dirty water on here because I have shame and it ...: Used it twice already and I have absolutely seen results. Not going to show you the dirty water on here because I have shame and it is gross. I will say that while you...</td>\n",
       "      <td>672</td>\n",
       "      <td>Not going to show you the dirty water on here because I have shame and it ...: Used it twice already and I have absolutely seen results. Not going to show you the dirty water on here because I have shame and it is gross. I will say that while you...</td>\n",
       "      <td>not going to show you the dirty water on here because i have shame and it ...: used it twice already and i have absolutely seen results. not going to show you the dirty water on here because i have shame and it is gross. i will say that while you...</td>\n",
       "      <td>[not, going, to, show, you, the, dirty, water, on, here, because, i, have, shame, and, it, ..., :, used, it, twice, already, and, i, have, absolutely, seen, results, ., not, going, to, show, you, the, dirty, water, on, here, because, i, have, sha...</td>\n",
       "      <td>[going, show, dirty, water, shame, ..., :, used, twice, already, absolutely, seen, results, ., going, show, dirty, water, shame, gross, ., say, 're, cleaning, ,, leave, place, second, (, instance, ,, 're, moving, plug, new, outlet, ), ,, leak, li...</td>\n",
       "      <td>[going, show, dirty, water, shame, ..., used, twice, already, absolutely, seen, results, going, show, dirty, water, shame, gross, say, 're, cleaning, leave, place, second, instance, 're, moving, plug, new, outlet, leak, little, water, part, sucks...</td>\n",
       "      <td>[go, dirty, water, shame, twice, absolutely, see, result, go, dirty, water, shame, gross, clean, leave, place, second, instance, move, plug, new, outlet, leak, little, water, suck, upward, big, deal, suck, right, happen, end, cleaning, remove, ta...</td>\n",
       "      <td>[(go, dirty), (dirty, water), (water, shame), (shame, twice), (twice, absolutely), (absolutely, see), (see, result), (result, go), (go, dirty), (dirty, water), (water, shame), (shame, gross), (gross, clean), (clean, leave), (leave, place), (place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Makes carpet look brand new!!!: When you get the shampooer you have to put it together but is very easy...the handle is the only thing that you have to attach...\\n\\n My carpets were very dirty because I have 2 small dogs that go in and hour all d...</td>\n",
       "      <td>1021</td>\n",
       "      <td>Makes carpet look brand new!!!: When you get the shampooer you have to put it together but is very easy...the handle is the only thing that you have to attach...\\n\\n My carpets were very dirty because I have 2 small dogs that go in and hour all d...</td>\n",
       "      <td>makes carpet look brand new!!!: when you get the shampooer you have to put it together but is very easy...the handle is the only thing that you have to attach...\\n\\n my carpets were very dirty because i have 2 small dogs that go in and hour all d...</td>\n",
       "      <td>[makes, carpet, look, brand, new, !, !, !, :, when, you, get, the, shampooer, you, have, to, put, it, together, but, is, very, easy, ..., the, handle, is, the, only, thing, that, you, have, to, attach, ..., my, carpets, were, very, dirty, because...</td>\n",
       "      <td>[makes, carpet, look, brand, new, !, !, !, :, get, shampooer, put, together, easy, ..., handle, thing, attach, ..., carpets, dirty, 2, small, dogs, go, hour, day, ..., 1st, day, got, shampoo, shampooed, entire, house, made, huge, difference, ., w...</td>\n",
       "      <td>[makes, carpet, look, brand, new, get, shampooer, put, together, easy, ..., handle, thing, attach, ..., carpets, dirty, 2, small, dogs, go, hour, day, ..., 1st, day, got, shampoo, shampooed, entire, house, made, huge, difference, week, later, dow...</td>\n",
       "      <td>[make, carpet, look, brand, new, shampooer, easy, handle, thing, attach, carpet, dirty, 2, small, dog, hour, day, 1st, day, get, shampoo, shampoo, entire, house, huge, difference, week, later, downstair, dirt, carpet, shampoo, carpet, look, brian...</td>\n",
       "      <td>[(make, carpet), (carpet, look), (look, brand), (brand, new), (new, shampooer), (shampooer, easy), (easy, handle), (handle, thing), (thing, attach), (attach, carpet), (carpet, dirty), (dirty, 2), (2, small), (small, dog), (dog, hour), (hour, day)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I Got What I Paid For: After getting an estimate on how much it would cost to have a \"professional\" clean our sofa &amp; love seat I decided to do it myself, so purchased this cleaner.  I chose this Hoover based on the many Amazon reviews I read, pri...</td>\n",
       "      <td>3016</td>\n",
       "      <td>I Got What I Paid For: After getting an estimate on how much it would cost to have a \"professional\" clean our sofa &amp; love seat I decided to do it myself, so purchased this cleaner.  I chose this Hoover based on the many Amazon reviews I read, pri...</td>\n",
       "      <td>i got what i paid for: after getting an estimate on how much it would cost to have a \"professional\" clean our sofa &amp; love seat i decided to do it myself, so purchased this cleaner.  i chose this hoover based on the many amazon reviews i read, pri...</td>\n",
       "      <td>[i, got, what, i, paid, for, :, after, getting, an, estimate, on, how, much, it, would, cost, to, have, a, ``, professional, '', clean, our, sofa, &amp;, love, seat, i, decided, to, do, it, myself, ,, so, purchased, this, cleaner, ., i, chose, this, ...</td>\n",
       "      <td>[got, paid, :, getting, estimate, much, would, cost, ``, professional, '', clean, sofa, &amp;, love, seat, decided, ,, purchased, cleaner, ., chose, hoover, based, many, amazon, reviews, read, ,, price, ,, reputation, maker, ., arrived, time, ,, pack...</td>\n",
       "      <td>[got, paid, getting, estimate, much, would, cost, ``, professional, '', clean, sofa, love, seat, decided, purchased, cleaner, chose, hoover, based, many, amazon, reviews, read, price, reputation, maker, arrived, time, packaging, great, thanks, am...</td>\n",
       "      <td>[got, pay, get, estimate, cost, professional, clean, sofa, love, seat, decide, purchase, cleaner, choose, hoover, base, amazon, review, read, price, reputation, maker, arrive, time, packaging, great, thank, amazon, cleaner, brand, new, condition,...</td>\n",
       "      <td>[(got, pay), (pay, get), (get, estimate), (estimate, cost), (cost, professional), (professional, clean), (clean, sofa), (sofa, love), (love, seat), (seat, decide), (decide, purchase), (purchase, cleaner), (cleaner, choose), (choose, hoover), (hoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Read tips before use, but overall great product: I purchased this Hoover carpet cleaner, because of all the great reviews on here.  I really like this carpet cleaner, and it really helped my poor tan colored carpet.  I have a dog, two cats, toddl...</td>\n",
       "      <td>995</td>\n",
       "      <td>Read tips before use, but overall great product: I purchased this Hoover carpet cleaner, because of all the great reviews on here.  I really like this carpet cleaner, and it really helped my poor tan colored carpet.  I have a dog, two cats, toddl...</td>\n",
       "      <td>read tips before use, but overall great product: i purchased this hoover carpet cleaner, because of all the great reviews on here.  i really like this carpet cleaner, and it really helped my poor tan colored carpet.  i have a dog, two cats, toddl...</td>\n",
       "      <td>[read, tips, before, use, ,, but, overall, great, product, :, i, purchased, this, hoover, carpet, cleaner, ,, because, of, all, the, great, reviews, on, here, ., i, really, like, this, carpet, cleaner, ,, and, it, really, helped, my, poor, tan, c...</td>\n",
       "      <td>[read, tips, use, ,, overall, great, product, :, purchased, hoover, carpet, cleaner, ,, great, reviews, ., really, like, carpet, cleaner, ,, really, helped, poor, tan, colored, carpet, ., dog, ,, two, cats, ,, toddler, ,, husband, ,, personally, ...</td>\n",
       "      <td>[read, tips, use, overall, great, product, purchased, hoover, carpet, cleaner, great, reviews, really, like, carpet, cleaner, really, helped, poor, tan, colored, carpet, dog, two, cats, toddler, husband, personally, beverage, spiller, pros, high,...</td>\n",
       "      <td>[read, tip, use, overall, great, product, purchase, hoover, carpet, cleaner, great, review, like, carpet, cleaner, help, poor, tan, color, carpet, dog, cat, toddler, husband, personally, beverage, spiller, pro, high, suction, heavy, clean, con, c...</td>\n",
       "      <td>[(read, tip), (tip, use), (use, overall), (overall, great), (great, product), (product, purchase), (purchase, hoover), (hoover, carpet), (carpet, cleaner), (cleaner, great), (great, review), (review, like), (like, carpet), (carpet, cleaner), (cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>VERY DISAPPOINTED: WORKED for maybe 1/2 hr and then it appeared the motor got hot and shut off and 10 secs later would start again and would work for 10 or 15 secs and quit again.......sending it back to HOOVER this week......I was VERY DISAPPOIN...</td>\n",
       "      <td>311</td>\n",
       "      <td>VERY DISAPPOINTED: WORKED for maybe 1/2 hr and then it appeared the motor got hot and shut off and 10 secs later would start again and would work for 10 or 15 secs and quit again.......sending it back to HOOVER this week......I was VERY DISAPPOIN...</td>\n",
       "      <td>very disappointed: worked for maybe 1/2 hr and then it appeared the motor got hot and shut off and 10 secs later would start again and would work for 10 or 15 secs and quit again.......sending it back to hoover this week......i was very disappoin...</td>\n",
       "      <td>[very, disappointed, :, worked, for, maybe, 1/2, hr, and, then, it, appeared, the, motor, got, hot, and, shut, off, and, 10, secs, later, would, start, again, and, would, work, for, 10, or, 15, secs, and, quit, again, ......., sending, it, back, ...</td>\n",
       "      <td>[disappointed, :, worked, maybe, 1/2, hr, appeared, motor, got, hot, shut, 10, secs, later, would, start, would, work, 10, 15, secs, quit, ......., sending, back, hoover, week, ......, disappointed, cause, reviews, good, ....., maybe, got, lemon,...</td>\n",
       "      <td>[disappointed, worked, maybe, 1/2, hr, appeared, motor, got, hot, shut, 10, secs, later, would, start, would, work, 10, 15, secs, quit, ......., sending, back, hoover, week, ......, disappointed, cause, reviews, good, ....., maybe, got, lemon]</td>\n",
       "      <td>[disappointed, worked, maybe, 1/2, hr, appear, motor, get, hot, shut, 10, sec, later, start, work, 10, 15, sec, quit, send, hoover, week, disappointed, cause, review, good, maybe, get, lemon]</td>\n",
       "      <td>[(disappointed, worked), (worked, maybe), (maybe, 1/2), (1/2, hr), (hr, appear), (appear, motor), (motor, get), (get, hot), (hot, shut), (shut, 10), (10, sec), (sec, later), (later, start), (start, work), (work, 10), (10, 15), (15, sec), (sec, qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  \\\n",
       "0      4.0   \n",
       "1      5.0   \n",
       "2      4.0   \n",
       "3      4.0   \n",
       "4      1.0   \n",
       "\n",
       "                                                                                                                                                                                                                                                    text-raw  \\\n",
       "0  Not going to show you the dirty water on here because I have shame and it ...: Used it twice already and I have absolutely seen results. Not going to show you the dirty water on here because I have shame and it is gross. I will say that while you...   \n",
       "1  Makes carpet look brand new!!!: When you get the shampooer you have to put it together but is very easy...the handle is the only thing that you have to attach...\\n\\n My carpets were very dirty because I have 2 small dogs that go in and hour all d...   \n",
       "2  I Got What I Paid For: After getting an estimate on how much it would cost to have a \"professional\" clean our sofa & love seat I decided to do it myself, so purchased this cleaner.  I chose this Hoover based on the many Amazon reviews I read, pri...   \n",
       "3  Read tips before use, but overall great product: I purchased this Hoover carpet cleaner, because of all the great reviews on here.  I really like this carpet cleaner, and it really helped my poor tan colored carpet.  I have a dog, two cats, toddl...   \n",
       "4  VERY DISAPPOINTED: WORKED for maybe 1/2 hr and then it appeared the motor got hot and shut off and 10 secs later would start again and would work for 10 or 15 secs and quit again.......sending it back to HOOVER this week......I was VERY DISAPPOIN...   \n",
       "\n",
       "   length  \\\n",
       "0     672   \n",
       "1    1021   \n",
       "2    3016   \n",
       "3     995   \n",
       "4     311   \n",
       "\n",
       "                                                                                                                                                                                                                                                        text  \\\n",
       "0  Not going to show you the dirty water on here because I have shame and it ...: Used it twice already and I have absolutely seen results. Not going to show you the dirty water on here because I have shame and it is gross. I will say that while you...   \n",
       "1  Makes carpet look brand new!!!: When you get the shampooer you have to put it together but is very easy...the handle is the only thing that you have to attach...\\n\\n My carpets were very dirty because I have 2 small dogs that go in and hour all d...   \n",
       "2  I Got What I Paid For: After getting an estimate on how much it would cost to have a \"professional\" clean our sofa & love seat I decided to do it myself, so purchased this cleaner.  I chose this Hoover based on the many Amazon reviews I read, pri...   \n",
       "3  Read tips before use, but overall great product: I purchased this Hoover carpet cleaner, because of all the great reviews on here.  I really like this carpet cleaner, and it really helped my poor tan colored carpet.  I have a dog, two cats, toddl...   \n",
       "4  VERY DISAPPOINTED: WORKED for maybe 1/2 hr and then it appeared the motor got hot and shut off and 10 secs later would start again and would work for 10 or 15 secs and quit again.......sending it back to HOOVER this week......I was VERY DISAPPOIN...   \n",
       "\n",
       "                                                                                                                                                                                                                                                  lower_text  \\\n",
       "0  not going to show you the dirty water on here because i have shame and it ...: used it twice already and i have absolutely seen results. not going to show you the dirty water on here because i have shame and it is gross. i will say that while you...   \n",
       "1  makes carpet look brand new!!!: when you get the shampooer you have to put it together but is very easy...the handle is the only thing that you have to attach...\\n\\n my carpets were very dirty because i have 2 small dogs that go in and hour all d...   \n",
       "2  i got what i paid for: after getting an estimate on how much it would cost to have a \"professional\" clean our sofa & love seat i decided to do it myself, so purchased this cleaner.  i chose this hoover based on the many amazon reviews i read, pri...   \n",
       "3  read tips before use, but overall great product: i purchased this hoover carpet cleaner, because of all the great reviews on here.  i really like this carpet cleaner, and it really helped my poor tan colored carpet.  i have a dog, two cats, toddl...   \n",
       "4  very disappointed: worked for maybe 1/2 hr and then it appeared the motor got hot and shut off and 10 secs later would start again and would work for 10 or 15 secs and quit again.......sending it back to hoover this week......i was very disappoin...   \n",
       "\n",
       "                                                                                                                                                                                                                                                      tokens  \\\n",
       "0  [not, going, to, show, you, the, dirty, water, on, here, because, i, have, shame, and, it, ..., :, used, it, twice, already, and, i, have, absolutely, seen, results, ., not, going, to, show, you, the, dirty, water, on, here, because, i, have, sha...   \n",
       "1  [makes, carpet, look, brand, new, !, !, !, :, when, you, get, the, shampooer, you, have, to, put, it, together, but, is, very, easy, ..., the, handle, is, the, only, thing, that, you, have, to, attach, ..., my, carpets, were, very, dirty, because...   \n",
       "2  [i, got, what, i, paid, for, :, after, getting, an, estimate, on, how, much, it, would, cost, to, have, a, ``, professional, '', clean, our, sofa, &, love, seat, i, decided, to, do, it, myself, ,, so, purchased, this, cleaner, ., i, chose, this, ...   \n",
       "3  [read, tips, before, use, ,, but, overall, great, product, :, i, purchased, this, hoover, carpet, cleaner, ,, because, of, all, the, great, reviews, on, here, ., i, really, like, this, carpet, cleaner, ,, and, it, really, helped, my, poor, tan, c...   \n",
       "4  [very, disappointed, :, worked, for, maybe, 1/2, hr, and, then, it, appeared, the, motor, got, hot, and, shut, off, and, 10, secs, later, would, start, again, and, would, work, for, 10, or, 15, secs, and, quit, again, ......., sending, it, back, ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                    no_stops  \\\n",
       "0  [going, show, dirty, water, shame, ..., :, used, twice, already, absolutely, seen, results, ., going, show, dirty, water, shame, gross, ., say, 're, cleaning, ,, leave, place, second, (, instance, ,, 're, moving, plug, new, outlet, ), ,, leak, li...   \n",
       "1  [makes, carpet, look, brand, new, !, !, !, :, get, shampooer, put, together, easy, ..., handle, thing, attach, ..., carpets, dirty, 2, small, dogs, go, hour, day, ..., 1st, day, got, shampoo, shampooed, entire, house, made, huge, difference, ., w...   \n",
       "2  [got, paid, :, getting, estimate, much, would, cost, ``, professional, '', clean, sofa, &, love, seat, decided, ,, purchased, cleaner, ., chose, hoover, based, many, amazon, reviews, read, ,, price, ,, reputation, maker, ., arrived, time, ,, pack...   \n",
       "3  [read, tips, use, ,, overall, great, product, :, purchased, hoover, carpet, cleaner, ,, great, reviews, ., really, like, carpet, cleaner, ,, really, helped, poor, tan, colored, carpet, ., dog, ,, two, cats, ,, toddler, ,, husband, ,, personally, ...   \n",
       "4  [disappointed, :, worked, maybe, 1/2, hr, appeared, motor, got, hot, shut, 10, secs, later, would, start, would, work, 10, 15, secs, quit, ......., sending, back, hoover, week, ......, disappointed, cause, reviews, good, ....., maybe, got, lemon,...   \n",
       "\n",
       "                                                                                                                                                                                                                                           no_stops_no_punct  \\\n",
       "0  [going, show, dirty, water, shame, ..., used, twice, already, absolutely, seen, results, going, show, dirty, water, shame, gross, say, 're, cleaning, leave, place, second, instance, 're, moving, plug, new, outlet, leak, little, water, part, sucks...   \n",
       "1  [makes, carpet, look, brand, new, get, shampooer, put, together, easy, ..., handle, thing, attach, ..., carpets, dirty, 2, small, dogs, go, hour, day, ..., 1st, day, got, shampoo, shampooed, entire, house, made, huge, difference, week, later, dow...   \n",
       "2  [got, paid, getting, estimate, much, would, cost, ``, professional, '', clean, sofa, love, seat, decided, purchased, cleaner, chose, hoover, based, many, amazon, reviews, read, price, reputation, maker, arrived, time, packaging, great, thanks, am...   \n",
       "3  [read, tips, use, overall, great, product, purchased, hoover, carpet, cleaner, great, reviews, really, like, carpet, cleaner, really, helped, poor, tan, colored, carpet, dog, two, cats, toddler, husband, personally, beverage, spiller, pros, high,...   \n",
       "4        [disappointed, worked, maybe, 1/2, hr, appeared, motor, got, hot, shut, 10, secs, later, would, start, would, work, 10, 15, secs, quit, ......., sending, back, hoover, week, ......, disappointed, cause, reviews, good, ....., maybe, got, lemon]   \n",
       "\n",
       "                                                                                                                                                                                                                                                spacy_lemmas  \\\n",
       "0  [go, dirty, water, shame, twice, absolutely, see, result, go, dirty, water, shame, gross, clean, leave, place, second, instance, move, plug, new, outlet, leak, little, water, suck, upward, big, deal, suck, right, happen, end, cleaning, remove, ta...   \n",
       "1  [make, carpet, look, brand, new, shampooer, easy, handle, thing, attach, carpet, dirty, 2, small, dog, hour, day, 1st, day, get, shampoo, shampoo, entire, house, huge, difference, week, later, downstair, dirt, carpet, shampoo, carpet, look, brian...   \n",
       "2  [got, pay, get, estimate, cost, professional, clean, sofa, love, seat, decide, purchase, cleaner, choose, hoover, base, amazon, review, read, price, reputation, maker, arrive, time, packaging, great, thank, amazon, cleaner, brand, new, condition,...   \n",
       "3  [read, tip, use, overall, great, product, purchase, hoover, carpet, cleaner, great, review, like, carpet, cleaner, help, poor, tan, color, carpet, dog, cat, toddler, husband, personally, beverage, spiller, pro, high, suction, heavy, clean, con, c...   \n",
       "4                                                            [disappointed, worked, maybe, 1/2, hr, appear, motor, get, hot, shut, 10, sec, later, start, work, 10, 15, sec, quit, send, hoover, week, disappointed, cause, review, good, maybe, get, lemon]   \n",
       "\n",
       "                                                                                                                                                                                                                                                     bigrams  \n",
       "0  [(go, dirty), (dirty, water), (water, shame), (shame, twice), (twice, absolutely), (absolutely, see), (see, result), (result, go), (go, dirty), (dirty, water), (water, shame), (shame, gross), (gross, clean), (clean, leave), (leave, place), (place...  \n",
       "1  [(make, carpet), (carpet, look), (look, brand), (brand, new), (new, shampooer), (shampooer, easy), (easy, handle), (handle, thing), (thing, attach), (attach, carpet), (carpet, dirty), (dirty, 2), (2, small), (small, dog), (dog, hour), (hour, day)...  \n",
       "2  [(got, pay), (pay, get), (get, estimate), (estimate, cost), (cost, professional), (professional, clean), (clean, sofa), (sofa, love), (love, seat), (seat, decide), (decide, purchase), (purchase, cleaner), (cleaner, choose), (choose, hoover), (hoo...  \n",
       "3  [(read, tip), (tip, use), (use, overall), (overall, great), (great, product), (product, purchase), (purchase, hoover), (hoover, carpet), (carpet, cleaner), (cleaner, great), (great, review), (review, like), (like, carpet), (carpet, cleaner), (cle...  \n",
       "4  [(disappointed, worked), (worked, maybe), (maybe, 1/2), (1/2, hr), (hr, appear), (appear, motor), (motor, get), (get, hot), (hot, shut), (shut, 10), (10, sec), (sec, later), (later, start), (start, work), (work, 10), (10, 15), (15, sec), (sec, qu...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "df = joblib.load('../Data-AmazonReviews/processed_data.joblib')\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88999b3f-1b93-49ee-950b-9f0bdb426be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_groups(x):\n",
    "    if x>=5.0:\n",
    "        return \"high\"\n",
    "    elif x <=2.0:\n",
    "        return \"low\"\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f5e92-f195-4ded-ac66-934ecb6644a2",
   "metadata": {},
   "source": [
    "To understand what customers do and do not like about Hoover products, we will define 2 groups:\n",
    "- High Ratings\n",
    "    - Overall rating = 5.0\n",
    "- Low Ratings\n",
    "    - Overall rating = 1.0 or 2.0\n",
    "\n",
    "\n",
    "We can use a function and .map to define group names based on the numeric overall ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cda1d0b-e442-4f09-b334-c3397ab11834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high    5547\n",
       "None    1832\n",
       "low      812\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use the function to create a new \"rating\" column with groups\n",
    "df['rating'] = df['overall'].map(create_groups)\n",
    "df['rating'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5caeeaad-6db4-4dbf-a9e2-fcd3dfd30334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high    0.872307\n",
       "low     0.127693\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check class balance of 'rating'\n",
    "df['rating'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34a9010c-9582-42e3-b958-507c65ad08fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall              0\n",
       "text-raw             0\n",
       "length               0\n",
       "text                 0\n",
       "lower_text           0\n",
       "tokens               0\n",
       "no_stops             0\n",
       "no_stops_no_punct    0\n",
       "spacy_lemmas         0\n",
       "bigrams              0\n",
       "rating               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a df_ml without null ratings\n",
    "df_ml = df.dropna(subset=['rating']).copy()\n",
    "df_ml.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cd85e99-a07d-4475-9d20-134e1695c248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     Makes carpet look brand new!!!: When you get the shampooer you have to put it together but is very easy...the handle is the only thing that you have to attach...\\n\\n My carpets were very dirty because I have 2 small dogs that go in and hour all d...\n",
       "4     VERY DISAPPOINTED: WORKED for maybe 1/2 hr and then it appeared the motor got hot and shut off and 10 secs later would start again and would work for 10 or 15 secs and quit again.......sending it back to HOOVER this week......I was VERY DISAPPOIN...\n",
       "5                                                                 Perfect!: I love this cleaner!  It's easy to operate, light enough to manipulate and easy to clean. The tank holds plenty of shampoo and water solution and the suction for removal is great.\n",
       "6     Wow - way exceeded expectations: I had the older model from probably 2001 and it was great for the occasional pet stain or the muddy paw prints on white carpet situation, but it was not for routine cleaning.  It finally konked out so bought this ...\n",
       "7     Nice Carpet Machine!: This machine works really well, both putting out the solution and then sucking it back up.  The pieces to it are durable and fit well together.  It is not clumsy.  I shampooed my living room and family room carpet in about 2...\n",
       "8     Great Product: This steamvac is easy to use, does an excellent job.  Changing water is a breeze.  The scrub brushes really \"rough up\" the carpet to get it clean.  Seems to have done a better job than anything else I have used, since the carpet is...\n",
       "9     Not good for major clean ups: We've had to use this three times now - once was for generally sanitizing a reasonably clean carpet following a kiddie get-together. The second time was for a peeing incident and it worked less well. We could detect ...\n",
       "11    Great Value: We had not washed our carpets in years and this cleaner did a great job.  The liquid containers could be a bit bigger however for this price we have no complaints.  It cleaned up every spot and high traffic area.  I was impressed tha...\n",
       "12                                                                                                      Cleans good: Does a good job cleaning. I have had a few hoover cleaners over the years, this one is a little more simple but does what I need it to do.\n",
       "14    Easy to set up and use - and a reasonable price!: We needed to replace our very old canister green machine, which worked well but was a hassle to set up for use.  We considered the green machine upright but it was twice the price of this one, whi...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## X - Option A)  lemmas\n",
    "# def join_tokens(token_list):\n",
    "#     joined_tokens = ' '.join(token_list)\n",
    "#     return joined_tokens\n",
    "# X = df_ml['spacy_lemmas'].apply(join_tokens)\n",
    "\n",
    "# X - Option B) original raw text\n",
    "X = df_ml['text']\n",
    "\n",
    "# y - use our binary target \n",
    "y = df_ml['rating']\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea038ef0-08da-4dc5-b7b3-41f4652ca28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high    0.872307\n",
       "low     0.127693\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde1fe33-1460-4d18-8ffe-8eb4ca9c6cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06184dc5-7b95-415d-ad4a-01b24f877d2a",
   "metadata": {},
   "source": [
    "# 📚 New For Today:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dd218e-3911-49e7-9776-c07dc9087ae2",
   "metadata": {},
   "source": [
    "- Starting with a simple train-test-split for ML model (like in movie nlp project)\n",
    "- Resampling Imbalanced training data\n",
    "- Creating tensorflow dataset from X_train, y_train (so dataset is rebalanced)\n",
    "- Creating tensorflow dataset (intended to be split in 2 ) for X_test and y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2486c413-1286-46df-b939-b6cc423e9b4e",
   "metadata": {},
   "source": [
    "## From Train-Test Split for ML to Train-Test-Val Split for ANNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f9c6b64-a923-4bcd-a899-8d1c43181cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4451, 1908)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform 70:30 train test split\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "len(X_train_full), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5dc81c-53c6-486c-9beb-1ba5a86f6909",
   "metadata": {},
   "source": [
    "### Using Sklearn's LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f3486-8db8-4486-b931-bdc11d14a662",
   "metadata": {},
   "source": [
    "- Can't use text labels with neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f098d599-e5a0-4d07-b8aa-a61ae8659921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3889    high\n",
       "3254    high\n",
       "2996    high\n",
       "3790    high\n",
       "3764    high\n",
       "7301    high\n",
       "2449    high\n",
       "430     high\n",
       "2296    high\n",
       "2321     low\n",
       "Name: rating, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4195576-f430-446b-853a-da86d2bf0322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instansiate label encoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the training target\n",
    "y_train_full_enc = encoder.fit_transform(y_train_full)#.values)\n",
    "\n",
    "# Fit and tranform the test target\n",
    "y_test_enc = encoder.transform(y_test)\n",
    "\n",
    "y_train_full_enc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2b8926d-f87c-40dd-b883-6ab44f054b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['high', 'low'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original Class names saved as .classes_\n",
    "classes = encoder.classes_\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a552b075-6d94-4ad7-8c05-025d60ac00c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['high', 'low'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can inverse-transform \n",
    "encoder.inverse_transform([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7cb1dc-d13d-4dcb-80ca-b8301f0f3581",
   "metadata": {},
   "source": [
    "### Undersampling Majority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25d98790-5804-4162-9e78-4b0b3ff8faa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Instantiate a RandomUnderSampler\n",
    "sampler = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14d977d4-e6a1-4bf1-8b84-b50c216f0fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ValueError('Expected 2D array, got 1D array instead:\\narray=[\\'Really like it!: Love this!  No more pulling out the vacuum cleaner from the garage and plugging it in 3 different places to get the whole room.  Suction is great, very compact and nice handling.  We will see if it holds up.  I did buy the extended warranty for 6 bucks due to some of the reviews.  But if I had to spend 100 on a new one every year I would.\\'\\n \\'which is awesome.: My last carpet cleaner broke so I bought this one after reading the reviews. It cleans very well! My carpet dries in about 30 minutes, which is awesome.\\'\\n \\'seriously powerful: This is our second of these vacuums- we liked the first so much that we decided to get a second one for the second floor of our house.  This is the only \"stick vac\" we have found that can compete with our Dyson. We have four cats, three birds, and a ten year old daughter with very long hair, plus a garden we track leaves and dirt in from, so we\\\\\\'re constantly (and I do mean constantly- at least twice a day) thoroughly vacuuming- I mean, going over the whole house. We usually do our big daily vacuuming of the whole house with the Dyson, but it\\\\\\'s a beast, and it\\\\\\'s not ideal for quick clean ups or, or lugging up the stairs, or doing what we call, \"zip ups\" throughout the day. This is the FIRST stick vac we have had that actually gets up all the hair plus any bird seed and dried leaves, and can make it through our whole house on a charge and continue to work powerfully. It\\\\\\'s also fairly lightweight (but not feather weight).\\\\n\\\\nIt would be nice if there was on board charging- that\\\\\\'s the ONLY major flaw with this vacuum- you have to take the battery out and put it in the charger to get a charge. And you\\\\\\'re not supposed to keep it in the charger, so you have to babysit the battery all the time. It\\\\\\'s be nice to have on-board charging, but alas...\\\\n\\\\nregardless, it\\\\\\'s the best lightweight vacuum we have found and we like it so much we now own two, and they regularly compete with the Dyson. I can\\\\\\'t recommend it enough.\\'\\n ...\\n \"No clean vacuum cleaner: Hard to get it to pick up the dog hair & sand. Dog hair clogs the opening which in turn won\\'t let it pick up the sand. I have to run across a rug to get the dog hair off so I can get what little sand it will pick up. Even with low cost, not worth the money.\"\\n \"Works great!: Works great.  So far I\\'ve used it 3 different times.  I\\'ve cleaned my carpets on 2 different days and furniture another day.  I noticed the most difference on the furniture (mostly because our carpets are dark brown shag and you can\\'t tell when they\\'re dirty) .  The spinning upholstery brush works great!  I did make the mistake of scrubbing cat throw up off the couch with the spin brush and I guess a granule got caught in the spin gears and it stopped spinning.  My husband was able to take it apart and get the grain out and it worked fine again.  So it\\'s important to vacuum any particles up before using the spin brush, but the other upholstery attachment had no issue sucking gobs of cat hair off the furniture.\\\\nI had no issues assembling the machine or with anything leaking.  Already went through the bottle of cleaning solution that came with it, but it was a small bottle.  I probably got 7-10 fills out of that bottle.  The instructions say to place the machine on a hard surface and let it suck up clean water to clean out the front suction part.  Man, does it suck up water well!  You can\\'t tell on carpets other than seeing the water being sucked through the machine.  But on hard floors, the floors are practically dry!  Will be great to have if our basement leaks again.\\\\nI figured for the cost of renting a machine twice, I could just own my own.  After reading reviews on several different machines, I\\'m happy I got this one.\"\\n \\'Researched and Researched and Researched: Researched and researched and researched and this was the result.\\\\n\\\\nSatisfied am I with the slim size, significant suck, and decent battery performance.\\'].\\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    X_train, y_train = sampler.fit_resample(X_train_full,y_train_full_enc)\n",
    "except Exception as e:\n",
    "    display(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e69b21c-e59a-44f2-9619-ec706e571518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit_resample on the reshaped X_train data and y-train data\n",
    "X_train, y_train_enc = sampler.fit_resample(X_train_full.values.reshape(-1,1),\n",
    "                                        y_train_full_enc)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b6157b-9f31-48fb-80d0-db4c35f5fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the reshaped X_train data back to 1D\n",
    "X_train = X_train.flatten()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3898e60d-cb19-408e-91d4-e677f033a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for class balance\n",
    "pd.Series(y_train_enc).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9880fe72-4a80-4135-ba02-1c2a5f873a21",
   "metadata": {},
   "source": [
    "## Previous Class' ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d319c2f9-60a7-4f4e-b2e2-acf0a1fe0f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b488903-2846-4bfc-a046-41ebb7ccebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a model pipeline \n",
    "count_pipe = Pipeline([('vectorizer',  CountVectorizer()), \n",
    "                       ('naivebayes',  MultinomialNB())])\n",
    "\n",
    "count_pipe.fit(X_train, y_train_enc)\n",
    "fn.evaluate_classification(count_pipe, X_train, y_train_enc, X_test, y_test_enc,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e80644-9fda-416e-80b6-789bb7a5903d",
   "metadata": {},
   "source": [
    "# Preparing For Deep NLP (Train-Test-Val Datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ef132d-e442-485e-a634-acf94bf541ea",
   "metadata": {},
   "source": [
    "## 🕹️ Prepare Tensorflow Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da20ab9e-7e58-445b-a0bf-38f9926e8d56",
   "metadata": {},
   "source": [
    "Since we already have train/test X and y vars, we will make 2 dataset objects using tf.data.Dataset.from_tensor_slices.\n",
    "\n",
    "1. The training dataset using X_train, y_train (that we resampled/balanced)\n",
    "2. The val/test dataset using X_test, y-test.\n",
    "\n",
    "We will then split the val/test dataset into a val/test split.\n",
    "\n",
    "<!-- \n",
    "### T/T/V Split - Order of Operations (if using 1 dataset object)\n",
    "\n",
    "1) **Create full dataset object & Shuffle Once.**\n",
    "2) Calculate number of samples for training and validation data.\n",
    "3) Create the train/test/val splits using .take() and .skip()\n",
    "4) **Add shuffle to the train dataset only.**\n",
    "5) (Optional/Not Used on LP) If applying a transformation (e.g. train_ds.map(...)) to the data, add  here, before .cache()\n",
    "7) (Optional) Add .cache() to all splits to increase speed  (but may cause problems with large datasets)\n",
    "8) **Add .batch to all splits (default batch size=32)**\n",
    "9) (Optional) Add .prefetch(tf.data.AUTOTUNE)\n",
    "10) (Optional) Print out final length of datasets -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0658b2a-2c35-4f27-a06e-a54416aa9821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training data to Dataset Object\n",
    "\n",
    "# Shuffle dataset once\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedeaafa-fa13-4309-a8a8-42913843b8c3",
   "metadata": {},
   "source": [
    "Create a test and validation dataset using X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e890160-24b8-4bcf-a3af-5d88bd0237a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test to dataset object to split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69060a8-96f1-4398-9242-af1b3701b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate # of samples for 50/50 val/test split\n",
    "n_val_samples = None\n",
    "n_val_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e495b3b9-b89e-41c8-b597-d65a383cddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform the val/test split\n",
    "\n",
    "## Create the validation dataset using .take\n",
    "\n",
    "\n",
    "## Create the test dataset using skip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad4a489-7074-49ea-be83-ea6c6f54cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the len gths of all 3 splits\n",
    "len(train_ds), len(val_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6305413-cb77-4238-9be5-f8ea32e7a9ee",
   "metadata": {},
   "source": [
    "### Adding Shuffling and Batching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66afce4b-e39e-458b-b022-ac39ed9ca9ef",
   "metadata": {},
   "source": [
    "Let's examine a single element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4678d3f-baba-4962-87cf-00910be748f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a sample single element \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9ebe2-9d41-4641-8961-88c3dfa7adf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (Repeat) display a sample single element \n",
    "example_X, example_y= train_ds.take(1).get_single_element()\n",
    "print(example_X,'\\n\\n',example_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27c52db3-92d2-4df6-822e-ee53198a20d8",
   "metadata": {},
   "source": [
    "Notice that we have the same example, the training data is not shuffling.\n",
    "\n",
    "Add .shuffle the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4969390-4e72-4e52-9fe7-41f83e683729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle only the training data every epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8b84c-a4b2-464e-a7ef-21e2891df7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Repeat) display a sample single element \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8caedf-696c-4284-a224-194e64319af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Repeat) display a sample single element \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b99b4bd-6d3c-409e-956b-a7d2e0fd5916",
   "metadata": {},
   "source": [
    "> Add batching (use 32 for batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48eeddb-5554-4f37-a435-91ea27911e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Setting the batch_size for all datasets\n",
    "\n",
    "# use .batch to add batching to all 3 datasets\n",
    "\n",
    "\n",
    "# Confirm the number of batches in each\n",
    "print (f' There are {len(train_ds)} training batches.')\n",
    "print (f' There are {len(val_ds)} validation batches.')\n",
    "print (f' There are {len(test_ds)} testing batches.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498f8eb-bdaa-45bb-a809-f36014e03f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Repeat) display a sample single element \n",
    "example_X, example_y= train_ds.take(1).get_single_element()\n",
    "print(example_X,'\\n\\n',example_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d48f3a6-6cb5-4065-9c49-4508e1f390c4",
   "metadata": {},
   "source": [
    "A single element now contains 32 samples since we set  batch_size to 32."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31a1990-85b6-4c25-852d-6049cae198a4",
   "metadata": {},
   "source": [
    "## 📚 Vectorizing Text with Keras's TextVectorization Layer (Demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d149c9a-8735-465b-b48a-ca8ba82dcee9",
   "metadata": {},
   "source": [
    "### TextVectorization Layer - Demo Count Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b16927-1276-4d6d-a209-64fed6bcfec6",
   "metadata": {},
   "source": [
    "Flexible layer that can convert text to bag-of-words or sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396378c7-cdc7-45d7-bacd-967abdf5f581",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create text Vectorization layer - set to count vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066c1dde-7d3a-4f62-ba2f-09fb5fd17194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the vocabulary from the vectorization layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db5f1c8-8f2f-47d9-a9e2-5bc9d232c247",
   "metadata": {},
   "source": [
    "- Before training, only contains the out of vocab token ([UNK])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb84974-50fe-466f-81d6-9e6a6f5a22cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text for demo \n",
    "example_text = ['Sometimes I love this vacuum, sometimes i hate this vacuum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc93a1b0-e470-4e79-8c91-9f3d58d5e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the vectorizer using .adapt\n",
    "\n",
    "# Check the vocabulary after training the layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6666ae7b-f4cc-43f8-ba87-294e7a99b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert example to count-vectorization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e2b3aa-03fb-4a4e-a9a4-2f4ab05acb7f",
   "metadata": {},
   "source": [
    "- Size of vectorized text - column for every word in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a37577f-0738-4836-89bd-392d3b4ffc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the counts as as DataFrame \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ec6f78-c06a-4299-95d1-6445ba7c8fd3",
   "metadata": {},
   "source": [
    "### TextVectorization Layer - Demo Sequence Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4376e380-0416-491a-a68a-417de91c3689",
   "metadata": {},
   "source": [
    "- Output_mode='int' returns sequences.\n",
    "- Length is set by data scientist, use 30 for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2aeb45-d8d4-4c6f-a11d-914b1a5f8e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text Vectorization layer for sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3381ee3-2a32-412d-bab6-61bf02edaf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the vocabulary of the new sequence vectorizer.\n",
    "vocab =  demo_sequence_vectorizer.get_vocabulary()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711794b0-ee24-4917-996f-33c59ef1b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the vectorizer using .adapt\n",
    "\n",
    "# Check the vocabulary after training the layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f19ae-86f6-4617-85fd-a68d8934a011",
   "metadata": {},
   "source": [
    "To demonstrate how sequences are used, we will make a dictionary with the integer code as the key and the corresponding word as the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d128654-ce00-4827-bd86-90737a54e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING VOCAB FOR DEMO\n",
    "# Getting list of vocab \n",
    "vocab = demo_sequence_vectorizer.get_vocabulary()\n",
    "\n",
    "# Save dictionaries to look up words from ints \n",
    "int_to_str  = {idx:word for idx, word in enumerate(vocab)} # Dictionary Comprehension\n",
    "int_to_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffffb57-fbe8-4c2f-9ad0-a1e138733fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert example to sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da990d10-2a75-4e0b-804e-a302b4f02bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot be made into a datafgrame\n",
    "try:\n",
    "    pd.DataFrame(sequences, columns = vocab)\n",
    "except Exception as e:\n",
    "    display(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04958dbd-126d-41a4-b63e-9a4e0e420d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the sequences as numpy array for the loop below\n",
    "sequences = sequences.numpy()\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abdad54-2f2b-42dc-ab07-5be556033ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each integer code, display the corresponding word\n",
    "for val in sequences[0]:\n",
    "    print(f\"{val} = {int_to_str[val]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a574b868-c730-4524-b129-c85f6ceb36ca",
   "metadata": {},
   "source": [
    "##  Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532cfa99-1ce6-4dbd-b02f-b331a1aa6f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Size of the Vocab\n",
    "VOCAB_SIZE = None\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed794019-1e9e-491a-8133-f9046d69de41",
   "metadata": {},
   "source": [
    "The embedding layer needs the number of words in the input (input_dim), and the desired embedding dimensions. (e.g. 100,200,300).\n",
    "\n",
    "Arbitrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262c208b-4130-4ce3-a4fc-a2ff082acd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding layer of desired # of values\n",
    "EMBED_DIM = 20\n",
    "embedding_layer = layers.Embedding(input_dim = VOCAB_SIZE, output_dim = EMBED_DIM)\n",
    "embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899e72fb-85c0-4886-8958-48785c41a0fc",
   "metadata": {},
   "source": [
    "### Demonstrating Sequence to Vector Embedding Lookup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e4b47-9546-4171-8c73-9965bed7b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum Model Needed to Create Embedding Layer for Vocab\n",
    "demo_embed = Sequential()\n",
    "demo_embed.add(demo_sequence_vectorizer)\n",
    "demo_embed.add(embedding_layer)\n",
    "demo_embed.compile(optimizer='adam', loss='mse')\n",
    "demo_embed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66623992-d44d-4838-a2e3-4c9e26bcfe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert example to sequences\n",
    "sequences = demo_sequence_vectorizer(example_text).numpy()\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4304d1d9-f7ce-4c77-bded-5cd634bb9988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding has row each word with EMBED_DIM of 100\n",
    "demo_sequence_vectorizer.vocabulary_size(), EMBED_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1031169-4d97-43d2-aa3d-1679b93fb34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the weights from the embedding layer (this is your actual embedding matrix)\n",
    "embedding_weights = demo_embed.layers[1].get_weights()[0]\n",
    "embedding_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051c73d1-12c4-4c64-b751-b706fd5925db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030ec9fe-6a68-4532-adfc-fee2263d228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "for val in sequences[0]:\n",
    "    print(f\"{val} = {int_to_str[val]}\")\n",
    "    print(embedding_weights[:,val])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5be88e-f906-4d45-a48e-aea90d1017df",
   "metadata": {},
   "source": [
    "### Word Vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc825c1d-f1b2-427e-8ed3-4fe627b2bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the words and their corresponding vectors\n",
    "vector_dict = {}\n",
    "for i, word in int_to_str.items():#tokenizer.word_index.items():\n",
    "    # Save the weights for word (based on numeric index)\n",
    "    vector_dict[word]= embedding_weights[i] \n",
    "\n",
    "    # vector_list.append(embedding_weights[i])\n",
    "vector_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804c401-996b-4386-8db4-dd585d5c56f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the vector for \"love\"\n",
    "vector_dict['love']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a9432-9aa5-4d33-9b3b-5dbe432773e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the vector for \"hate\"\n",
    "vector_dict['hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d419d9f-38e3-4f75-96ac-4a9cdc63cff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectors can be added/subtracted to get output vector - then find most similar word  \n",
    "vector_dict['hate'] + vector_dict['love'] + vector_dict['vacuum']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab650c-081c-44c6-afa4-33c234192bd7",
   "metadata": {},
   "source": [
    "## Word Embeddings Demo (Pre-Trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e12b1c6-ea27-41ab-bc5d-a00c296d9d4b",
   "metadata": {},
   "source": [
    "###  Pretrianed Word Embeddings with GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d247fc46-ace7-4a56-9fcd-d6236028aef6",
   "metadata": {},
   "source": [
    "- [Click here](https://nlp.stanford.edu/data/glove.6B.zip) to start donwnloading GloVe zip file (glove.6B.zip)\n",
    "- Unzip the downloaded zip archive.\n",
    "- Open the extracted folder and find the the `glove.6B.100d.txt` file. (Size is over 300MB )\n",
    "- Move the text file from Downloads to the same folder as this notebook.\n",
    "- **Make sure to ignore the large file using GitHub Desktop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d787ab9-41a7-4c09-bd99-76722f369f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# Load GloVe vectors into a gensim model\n",
    "glove_model = KeyedVectors.load_word2vec_format(\"glove.6B.100d.txt\", binary=False, no_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7859c359-c117-4d4c-b745-a5c0591c8ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can now use `glove_model` to access individual word vectors, similar to a dictionary\n",
    "vector = glove_model['king']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2cfa48-3101-4f11-b95f-86a2da36dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f16f619-2d0b-4443-869a-801a3fb40313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find similarity between words\n",
    "glove_model.similarity('king', 'queen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0366fee-7698-44a3-b281-1d55518ec2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform word math\n",
    "result = glove_model.most_similar(positive=['woman', 'king'], negative=['man'], topn=5)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc6bd42-f0a0-4ad0-a301-5790f22b24fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use glove to calculate the most similar\n",
    "glove_model.most_similar('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2631163a-290a-4086-8525-2ead60ae42ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually calculating new vector for word math\n",
    "new_vector = glove_model['king'] - glove_model['man'] + glove_model['woman']\n",
    "new_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee62f9b9-696b-4186-baa0-96306023a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using .most_similar with an array\n",
    "glove_model.most_similar(new_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4446cc69-1265-4e2e-a777-875ee070fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually calculating new vector for word math\n",
    "new_vector = glove_model['monarchy'] + glove_model['vote'] + glove_model['government']\n",
    "glove_model.most_similar(new_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccf957d-31af-4be4-aeeb-dc909a6a2c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually calculating new vector for word math\n",
    "new_vector = glove_model['baby'] + glove_model['age']\n",
    "glove_model.most_similar(new_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede594e-cd14-4cdd-85ad-19065d899744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Manually calculating new vector for word math\n",
    "new_vector = glove_model['baby'] + glove_model['baby']\n",
    "glove_model.most_similar(new_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f05532-5113-4208-9163-c933b816d7e1",
   "metadata": {},
   "source": [
    "# Returning to Hoover Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d401b00d-d9b2-416c-b171-2e3cace3dd92",
   "metadata": {},
   "source": [
    "### Create the Training Texts Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d5cc8b-963d-4a78-a33f-4f134509e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the layer on the training texts\n",
    "try:\n",
    "    sequence_vectorizer.adapt(train_ds)\n",
    "except Exception as e:\n",
    "    display(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45da873-5e7a-4e92-b4ca-939ad5c0e1f2",
   "metadata": {},
   "source": [
    "> We need to get a version of our data that is **only the texts**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a346be-2bf5-483d-8c13-4074fb506730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get just the text_ds from ds_train\n",
    "\n",
    "# Preview the text_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2ad04a-c1c2-4c5e-bfa7-f7ce64e7a536",
   "metadata": {},
   "source": [
    "### Determine appropriate sequence length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2fbbd2-718b-4766-912a-9fef9aa862ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ml['length (characters)'] = df_ml['text'].map(len)\n",
    "# df_ml.head(3)\n",
    "\n",
    "# ax = sns.histplot(data=df_ml, hue='rating', x='length (characters)',\n",
    "#                 stat='percent',common_norm=False)#, estimator='median',);\n",
    "# ax.axvline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9713fe-43cb-4bb9-aebc-e31601c543db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the length of the each text\n",
    "# We will split on each space, and then get the length\n",
    "df_ml['length (tokens)'] = df_ml['text'].map( lambda x: len(x.split(\" \")))\n",
    "df_ml['length (tokens)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e473f73c-0ac0-461e-a186-bf45ad560e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = None\n",
    "ax = sns.histplot(data=df_ml, hue='rating', x='length (tokens)',kde=True,\n",
    "                stat='probability',common_norm=False)#, estimator='median',);\n",
    "ax.axvline(SEQUENCE_LENGTH, color='red', ls=\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6aed55-e62e-4375-8d80-17223bcdb253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# # Define a function to calculate cosine similarity\n",
    "# def find_closest_embeddings(embedding):\n",
    "    \n",
    "#     return sorted(vector_dict.keys(), key=lambda word: cosine_similarity([vector_dict[word]], [embedding]))\n",
    "\n",
    "# # Example of finding words similar to 'vacuum' \n",
    "# similar_to_vacuum = find_closest_embeddings(vector_dict['vacuum'])[:5]  # Get the top 5 similar words\n",
    "\n",
    "# # Print the similar words\n",
    "# print(\"Words similar to 'vacuum':\", similar_to_vacuum)\n",
    "\n",
    "# # Demonstration of vector arithmetic: 'hate' + 'love' + 'vacuum'\n",
    "# combined_vector = vector_dict['hate'] + vector_dict['love'] + vector_dict['vacuum']\n",
    "# similar_to_combined = find_closest_embeddings(combined_vector)[:5]  # Get the top 5 similar words\n",
    "\n",
    "# # Print the similar words to the combined vector\n",
    "# print(\"Words similar to the combination of 'hate', 'love', and 'vacuum':\", similar_to_combined)\n",
    "# # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a628c644-cf83-4cd6-abe8-c181c3af2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Example of finding words similar to 'vacuum' \n",
    "# n_results = 5\n",
    "# demo_word = 'vacuum'\n",
    "# add_word = 'love'\n",
    "\n",
    "# similar_to_vacuum = find_closest_embeddings(vector_dict[demo_word])[:n_results]  # Get the top 5 similar words\n",
    "\n",
    "# # Print the similar words\n",
    "# print(f\"Words similar to '{demo_word}':\")\n",
    "# print(similar_to_vacuum)\n",
    "\n",
    "# # Demonstration of vector arithmetic: 'hate' + 'love' + 'vacuum'\n",
    "# combined_vector =vector_dict[add_word] + vector_dict[demo_word]# vector_dict['hate'] + \n",
    "\n",
    "# similar_to_combined = find_closest_embeddings(combined_vector)[:n_results]  # Get the top 5 similar words\n",
    "\n",
    "# # Print the similar words to the combined vector\n",
    "# print(f\"\\nWords similar to the combination of {demo_word} + {add_word}\")\n",
    "# print(similar_to_combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1a448-8cc1-4bac-8896-0d278ebcfc5f",
   "metadata": {},
   "source": [
    "# Our First Deep Sequence Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5530ad65-1a61-43b7-bbfa-0b9c9c42c6d1",
   "metadata": {},
   "source": [
    "### Combining the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95210b15-3546-48cb-9e2e-85669af45e6d",
   "metadata": {},
   "source": [
    "### Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46088607-41ee-49b1-93a4-d2405e591730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Create text Vectorization layer\n",
    "SEQUENCE_LENGTH = None\n",
    "EMBED_DIM = None\n",
    "\n",
    "sequence_vectorizer = tf.keras.layers.TextVectorization(\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=SEQUENCE_LENGTH\n",
    ")\n",
    "\n",
    "sequence_vectorizer.adapt(ds_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2873c9d2-f3f2-4b75-9230-c4caef9ebb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = sequence_vectorizer.vocabulary_size()\n",
    "\n",
    "\n",
    "# Define sequential model with pre-trained vectorization layer and *new* embedding layer\n",
    "model = Sequential([\n",
    "    sequence_vectorizer,\n",
    "    layers.Embedding(input_dim=VOCAB_SIZE,\n",
    "                              output_dim=EMBED_DIM, \n",
    "                              input_length=SEQUENCE_LENGTH)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8721207e-992b-449f-8892-f053704a70d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnn_model(text_vectorization_layer):\n",
    "    VOCAB_SIZE = text_vectorization_layer.vocabulary_size()\n",
    "    SEQUENCE_LENGTH = sequence_vectorizer.get_config()['output_sequence_length']\n",
    "    \n",
    "    \n",
    "    # Define sequential model with pre-trained vectorization layer and *new* embedding layer\n",
    "    model = Sequential([\n",
    "        text_vectorization_layer,\n",
    "        layers.Embedding(input_dim=VOCAB_SIZE,\n",
    "                                  output_dim=EMBED_DIM, \n",
    "                                  input_length=SEQUENCE_LENGTH)\n",
    "        ])\n",
    "        \n",
    "    # Add *new* LSTM layer\n",
    "    model.add(layers.SimpleRNN(32)) #BEST=32\n",
    "    \n",
    "    # Add output layer\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    " \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizers.legacy.Adam(learning_rate = .001), \n",
    "                  loss='bce',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def get_callbacks(patience=3, monitor='val_accuracy'):\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(patience=patience, monitor=monitor)\n",
    "    return [early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee5658e-544d-44ab-911a-4ded171ac3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the lstm model and specify the vectorizer\n",
    "rnn_model = build_rnn_model(sequence_vectorizer)\n",
    "\n",
    "# Defien number of epocs\n",
    "EPOCHS = 30\n",
    "# Fit the model\n",
    "history = rnn_model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=get_callbacks(patience=5),\n",
    ")\n",
    "fn.plot_history(history,figsize=(6,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb74a307-abc8-4713-bc8f-44ca51062faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the results\n",
    "results = fn.evaluate_classification_network(\n",
    "    rnn_model, X_train=train_ds, \n",
    "    X_test=test_ds,# history=history\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e273488b-df60-476b-9c46-8e376679e835",
   "metadata": {},
   "source": [
    "# Next Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd497e6f-a936-46c8-a175-920a5d729f98",
   "metadata": {},
   "source": [
    "> We will continue with this task and introduce and apply various sequence models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4543406c-f744-4ff0-9625-041f01863b59",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# APPENDIX - Save for Next Lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be57a84-b485-42c6-b580-f46ac5bd835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEMP/EXP - extract embedding matrix\n",
    "\n",
    "embedding_weights = rnn_model.layers[1].get_weights()[0]\n",
    "embedding_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5507d21-5512-4835-b99c-d9c6cdac338c",
   "metadata": {},
   "source": [
    "> - Conceptual example of using the maximum value as final result.\n",
    "> - Relate to GlovalMaxPooling1D() layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bffeeb-9b97-4fb0-a428-f7daefbdde9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the MAX values (relate to GlobalMaxPooling)\n",
    "max_vector = np.max((vector_dict['hate'], vector_dict['love'] ,vector_dict['vacuum']), axis=0)\n",
    "print(max_vector.shape)\n",
    "max_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d43288-b4bb-4145-a6ad-cb7efe7b5bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Average values (relate to GlobalMaxPooling)\n",
    "avg_vector = np.mean((vector_dict['hate'], vector_dict['love'] ,vector_dict['vacuum']), axis=0)\n",
    "print(avg_vector.shape)\n",
    "avg_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1d4c28-6334-4cfd-aa18-b05044c321e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
